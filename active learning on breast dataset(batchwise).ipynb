{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specify the size of training dataset: 6\n",
      "Specify the size of training dataset for active learn: 20\n",
      "Specify the size of testing dataset: 500\n",
      "Input the value of k: 4\n",
      "Specify the batch size: 5\n",
      "Specify the value of pre-filter: 7\n",
      "Accuracy for testcase  1 is:  77.2 %\n",
      "Accuracy for testcase  2 is:  88.0 %\n",
      "Accuracy for testcase  3 is:  89.0 %\n",
      "Accuracy for testcase  4 is:  80.80000000000001 %\n",
      "Accuracy for testcase  5 is:  89.8 %\n",
      "Accuracy for testcase  6 is:  88.6 %\n",
      "Accuracy for testcase  7 is:  91.2 %\n",
      "Accuracy for testcase  8 is:  83.0 %\n",
      "Accuracy for testcase  9 is:  83.2 %\n",
      "Accuracy for testcase  10 is:  88.2 %\n",
      "Accuracy for testcase  11 is:  81.6 %\n",
      "Accuracy for testcase  12 is:  84.6 %\n",
      "Accuracy for testcase  13 is:  86.8 %\n",
      "Accuracy for testcase  14 is:  77.8 %\n",
      "Accuracy for testcase  15 is:  88.0 %\n",
      "Overall mean is:  85.18666666666668 %\n"
     ]
    }
   ],
   "source": [
    "#active learning on wine dataset(batchwise)\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from scipy.spatial.distance import cdist\n",
    "from numpy.random import randint\n",
    "\n",
    "\n",
    "#kmeans \n",
    "def kmeans(samples_idx, n_clusters, x_input):\n",
    "    \n",
    "    centroids = x_input[np.random.choice(samples_idx, n_clusters, replace=False)]\n",
    "    for it in range(50): # perform 10 iterations of k-means clustering with updated centroids\n",
    "        dists = np.zeros((samples_idx, n_clusters))\n",
    "        for i in range(samples_idx):\n",
    "            for j in range(n_clusters):\n",
    "                dists[i][j] = np.linalg.norm(x_input[i]-centroids[j])\n",
    "        cluster_ids = np.argmin(dists, axis=1)\n",
    "        for c in range(n_clusters):\n",
    "            idx = np.where(cluster_ids == c)[0]\n",
    "            if len(idx) > 0:\n",
    "                centroids[c] = np.mean(x_input[idx], axis=0)\n",
    "     \n",
    "    return centroids\n",
    "#Euclidean Distance\n",
    "def eucledian(p1,p2):\n",
    "    dist = np.sqrt(np.sum((p1-p2)**2))\n",
    "    return dist\n",
    "\n",
    "#function to get closest point with clusters\n",
    "def closest(x_train, x_input):\n",
    "    op_labels = []\n",
    "     \n",
    "    #Loop through the Datapoints to be classified\n",
    "    for item in x_input: \n",
    "         \n",
    "        #Array to store distances\n",
    "        point_dist = []\n",
    "         \n",
    "        #Loop through each training Data\n",
    "        for j in range(len(x_train)): \n",
    "            distances = eucledian(np.array(x_train[j,:]) , item) \n",
    "            #Calculating the distance\n",
    "            point_dist.append(distances) \n",
    "        point_dist = np.array(point_dist) \n",
    "         \n",
    "        #Sorting the array while preserving the index\n",
    "        #Keeping the first K datapoints\n",
    "        dist = np.argmin(point_dist)\n",
    "        op_labels.append(dist)\n",
    " \n",
    "    return op_labels\n",
    " \n",
    "#Function to calculate KNN\n",
    "def predict(x_train, y , x_input, k):\n",
    "    op_labels = []\n",
    "     \n",
    "    #Loop through the Datapoints to be classified\n",
    "    for item in x_input: \n",
    "         \n",
    "        #Array to store distances\n",
    "        point_dist = []\n",
    "         \n",
    "        #Loop through each training Data\n",
    "        for j in range(len(x_train)): \n",
    "            distances = eucledian(np.array(x_train[j,:]) , item) \n",
    "            #Calculating the distance\n",
    "            point_dist.append(distances) \n",
    "        point_dist = np.array(point_dist) \n",
    "         \n",
    "        #Sorting the array while preserving the index\n",
    "        #Keeping the first K datapoints\n",
    "        dist = np.argsort(point_dist)[:k] \n",
    "         \n",
    "        #Labels of the K datapoints from above\n",
    "        labels = y[dist]\n",
    "         \n",
    "        #Majority voting\n",
    "        lab = mode(labels) \n",
    "        lab = lab.mode[0]\n",
    "        op_labels.append(lab)\n",
    " \n",
    "    return op_labels\n",
    "#function to calculate most ambiguas point\n",
    "def ambiguas(x_train, y , x_input, k, w, v):\n",
    "    op_labels = []\n",
    "     \n",
    "    #Loop through the Datapoints to be classified\n",
    "    for item in x_input: \n",
    "         \n",
    "        #Array to store distances\n",
    "        point_dist = []\n",
    "         \n",
    "        #Loop through each training Data\n",
    "        for j in range(len(x_train)): \n",
    "            distances = eucledian(np.array(x_train[j,:]) , item) \n",
    "            #Calculating the distance\n",
    "            point_dist.append(distances) \n",
    "        point_dist = np.array(point_dist) \n",
    "         \n",
    "        #Sorting the array while preserving the index\n",
    "        #Keeping the first K datapoints\n",
    "        dist = np.argsort(point_dist)[:k] \n",
    "        \n",
    "         \n",
    "        #Labels of the K datapoints from above\n",
    "        labels = y[dist]\n",
    "        \n",
    "        #majority\n",
    "        count0 = 0\n",
    "        count1 = 0\n",
    "        \n",
    "        for i in range(k):\n",
    "            if(labels[i] == 0):\n",
    "                count0 = count0+1\n",
    "            elif(labels[i] == 1):\n",
    "                count1 = count1+1\n",
    "            \n",
    "         \n",
    "        occur = [count0, count1]\n",
    "        \n",
    "        occur.sort(reverse = True)\n",
    "    \n",
    "        diff = (occur[0] - occur[1])/k\n",
    "        \n",
    "        #Majority voting\n",
    "        #lab = mode(labels) \n",
    "        #lab1 = lab.mode[0]\n",
    "        #lab3 = np.count_nonzero(labels == lab1)\n",
    "        #neww = [i for i in kabels if i!= lab1]\n",
    "        \n",
    "        #lab5 = mode(neww)\n",
    "        #lab2 = lab5.mode[0]\n",
    "        \n",
    "        #lab4 = np.count_nonzero(neww == lab2)\n",
    "        #diff = (lab3 - lab4)/k\n",
    "        \n",
    "        op_labels.append(diff)\n",
    "    op_labels = np.array(op_labels)\n",
    "    \n",
    "    j = np.argsort(op_labels)[:w*v]\n",
    "    pk = j.shape[0]\n",
    "#     c = x_input[j]\n",
    "    cluster = kmeans(pk,w,x_input)\n",
    "    \n",
    "#     print(type(cluster))\n",
    "#     print(type(x_input))\n",
    "#     cluster = cluster.tolist()\n",
    "#     x_input = x_input.tolist()\n",
    "#     print(type(cluster))\n",
    "#     print(type(x_input))\n",
    "#     print(cluster)\n",
    "#     print(x_input)\n",
    "    \n",
    "    indices = closest(x_input, cluster)\n",
    "    \n",
    "    \n",
    "#     for h in range(len(cluster)):\n",
    "#         new_item = np.where(cluster[h] == )\n",
    "    return indices\n",
    "\n",
    "\n",
    "\n",
    "def accu_scr(y_test, y_pred):\n",
    "    cnt = 0\n",
    "    for k in range(len(y_test)):\n",
    "        if(y_pred[k] == y_test[k]):\n",
    "            cnt = cnt+1\n",
    "    p = cnt/len(y_test)\n",
    "    \n",
    "    return p\n",
    "    \n",
    "\n",
    "\n",
    "#Loading the Data\n",
    "iris= load_breast_cancer()\n",
    " \n",
    "# Store features matrix in X\n",
    "X= iris.data\n",
    "\n",
    "\n",
    "#Store target vector in \n",
    "y= iris.target\n",
    "\n",
    "r = input(\"Specify the size of training dataset: \")\n",
    "n = input(\"Specify the size of training dataset for active learn: \")\n",
    "l = input(\"Specify the size of testing dataset: \")\n",
    "z = input(\"Input the value of k: \")\n",
    "u = input(\"Specify the batch size: \")\n",
    "v = input(\"Specify the value of pre-filter: \")\n",
    "\n",
    "# k = input(\"Input the value of k for active learning: \")\n",
    "\n",
    "counter = 0\n",
    "for g in range(15):\n",
    "    count = 0\n",
    "    arr = []\n",
    "    #Creating the training Data\n",
    "    train_idx = []\n",
    "    for p in range(2):\n",
    "        if(p == 0):\n",
    "            tt = xxx = randint(0 ,212 ,int(int(r)/2))\n",
    "        if(p == 1):\n",
    "            tt = xxx = randint(212 ,569 ,int(int(r)/2)) \n",
    "            \n",
    "            \n",
    "        for w in range(len(tt)):\n",
    "            train_idx.append(tt[w]) \n",
    "\n",
    "    X_train = X[train_idx]\n",
    "\n",
    "    y_train = y[train_idx]\n",
    "\n",
    "    T = X.copy()\n",
    "    S = y.copy()\n",
    "    f = int((int(n))/int(u))\n",
    "    index = []\n",
    "    index = np.array(index)\n",
    "\n",
    "    for b in range(f):\n",
    "        \n",
    "        index = ambiguas(X_train,y_train,T , int(z), int(u), int(v))\n",
    "        \n",
    "        X_train = np.append(X_train, T[index]).reshape(1,(int(r)+int(u)*(b + 1))*30).reshape(int(r)+int(u)*(b + 1),30)\n",
    "        y_train = np.append(y_train, S[index])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        T = np.delete(T, index, 0)\n",
    "        S = np.delete(S, index)\n",
    "\n",
    "\n",
    "    # indexes = ambiguas(X_train,y_train,X , int(k))\n",
    "    # indexes = np.array(indexes)\n",
    "    # print(indexes)\n",
    "\n",
    "\n",
    "\n",
    "    # new_indexes = np.argsort(indexes)[:int(n)]\n",
    "\n",
    "    # new_ind = new_indexes.tolist() + train_idx\n",
    "    # print(new_ind)\n",
    "    # X_t = X[new_ind]\n",
    "    # y_t = y[new_ind]\n",
    "\n",
    "    # print(y_t)\n",
    "\n",
    "    # X_tr = X_train + X_t\n",
    "    # y_tr = y_train + y_t\n",
    "\n",
    "\n",
    "    # for s in range(int(n)):\n",
    "    #     X_train.append(X_t[s])\n",
    "    #     y_train.append(y_t[s])\n",
    "    # # X_train = X[new_indexes]\n",
    "    # # y_train = y[new_indexes]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        #Creating the testing Data\n",
    "    test_idx = xxx = randint(0,178,int(l)) \n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "\n",
    "\n",
    "\n",
    "    #Applying the created function \n",
    "    y_pred = predict(X_train,y_train,X_test , int(z))\n",
    "    #Checking the accuracy\n",
    "    a = accu_scr(y_test, y_pred)\n",
    "    #keeping the value in an array\n",
    "    arr.append(a)\n",
    "\n",
    "    print(\"Accuracy for testcase \", g+1 ,\"is: \", a*100, \"%\" )\n",
    "\n",
    "    #calculating mean accuracy\n",
    "\n",
    "    \n",
    "     \n",
    "    counter = counter + a\n",
    "#     print(\"\\nAccuracy for iteration \", g ,\"is: \", (counter/*100,\"%\\n\") \n",
    "    \n",
    "overall_mean = counter/15\n",
    "print(\"Overall mean is: \", overall_mean*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
